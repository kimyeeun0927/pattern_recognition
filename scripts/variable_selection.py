import pandas as pd
import numpy as np
from sklearn.feature_selection import VarianceThreshold
from statsmodels.stats.outliers_influence import variance_inflation_factor
import os

def drop_outliers(df: pd.DataFrame, drop_path: str) -> pd.DataFrame:
    if os.path.exists(drop_path):
        rows_to_drop = pd.read_csv(drop_path, header=None).squeeze().tolist()
        df = df.drop(index=rows_to_drop)
        print(f"âœ… Dropped {len(rows_to_drop)} rows from train")
    else:
        print("âš ï¸ rows_to_drop.csv not found.")
    return df

def select_features(df: pd.DataFrame) -> list:
    dummy_cols = [col for col in df.columns if col.startswith('data_channel_') or col.startswith('weekday_')]
    numeric_cols = [col for col in df.columns if col not in dummy_cols and col not in {'id', 'shares', 'y'}]

    df_numeric = df[numeric_cols]

    # 1. ë¶„ì‚° ê¸°ì¤€ ì™„í™”
    vt = VarianceThreshold(threshold=0.0005)  # ê¸°ì¡´ 0.001ì—ì„œ ì™„í™”
    vt.fit(df_numeric)
    low_var = df_numeric.columns[~vt.get_support()]

    # 2. ìƒê´€ê³„ìˆ˜ ê¸°ì¤€ ì™„í™”
    corr = df_numeric.corr().abs()
    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))
    high_corr = [c for c in upper.columns if any(upper[c] > 0.98)]  # ê¸°ì¡´ 0.95ì—ì„œ ì™„í™”

    # 3. VIF ê¸°ì¤€ ì™„í™”
    vif_vals = [variance_inflation_factor(df_numeric.values, i) for i in range(df_numeric.shape[1])]
    vif_drop = df_numeric.columns[np.array(vif_vals) > 20]  # ê¸°ì¡´ 15ì—ì„œ ì™„í™”

    # 4. ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜ ë³´í˜¸
    protected_vars = {'kw_avg_min', 'global_sentiment_polarity'}
    drop_cols = set(low_var) | set(high_corr) | set(vif_drop) - protected_vars

    # 5. ìµœì¢… ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸
    final_numeric = [c for c in numeric_cols if c not in drop_cols]
    final_cols = final_numeric + dummy_cols
    return final_cols


if __name__ == "__main__":
    train_raw = pd.read_csv("data/train_encoded.csv")
    test = pd.read_csv("data/test_encoded.csv")

    # 1. ì´ìƒì¹˜ ì œê±°
    train_cleaned = drop_outliers(train_raw, "data/rows_to_drop.csv")

    # 2. y ë¶„ë¦¬
    y = train_cleaned['y']
    train_features_only = train_cleaned.drop(columns=['y'])

    # 3. ë³€ìˆ˜ ì„ íƒ
    selected_cols = select_features(train_cleaned)

    # 4. train: ì„ íƒëœ ì»¬ëŸ¼ + y ë³‘í•©
    X_train_selected = train_features_only[selected_cols]
    train_selected = pd.concat([X_train_selected, y], axis=1)
    train_selected.to_csv("data/train_selected.csv", index=False)

    # 5. test: ì„ íƒëœ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    test_selected = test[[col for col in selected_cols if col in test.columns]]
    test_selected.to_csv("data/test_selected.csv", index=False)

    # 6. ê²€ì¦
    print("\nğŸ§ª ê²°ê³¼ ê²€ì¦")
    print(f"ğŸ“Š train_selected: {train_selected.shape}")
    print(f"ğŸ“Š test_selected: {test_selected.shape}")

    if 'y' in test_selected.columns:
        raise ValueError("âŒ test_selectedì— 'y' ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŒ! ì œê±° í•„ìš” â—")

    mismatch = set(train_selected.columns) - {'y'} != set(test_selected.columns)
    if mismatch:
        print("âŒ ì»¬ëŸ¼ ë¶ˆì¼ì¹˜! y ì œì™¸í•˜ê³ ë„ êµ¬ì¡°ê°€ ë‹¤ë¦„")
        print("âš ï¸ train-only ì»¬ëŸ¼:", set(train_selected.columns) - set(test_selected.columns) - {'y'})
        print("âš ï¸ test-only ì»¬ëŸ¼:", set(test_selected.columns) - (set(train_selected.columns) - {'y'}))
    else:
        print("âœ… ì»¬ëŸ¼ êµ¬ì¡° ì¼ì¹˜ (y ì œì™¸)")

    # 7. ì¤‘ìš” ë³€ìˆ˜ ê²€ì¦
    print("\nğŸ” ì¤‘ìš” ë³€ìˆ˜ ê²€ì¦:")
    important_cols = ['kw_max_min', 'global_sentiment_polarity']
    missing_important = [col for col in important_cols if col not in train_selected.columns]
    if missing_important:
        print("âŒ ì¤‘ìš” ë³€ìˆ˜ ëˆ„ë½ë¨:", missing_important)
        raise ValueError("âš ï¸ ì¤‘ìš” ë³€ìˆ˜ê°€ trainì— ì—†ìŠµë‹ˆë‹¤ â€” ê¸°ì¤€ì„ ë‹¤ì‹œ ì¡°ì •í•˜ì„¸ìš”!")
    else:
        print("âœ… ì¤‘ìš” ë³€ìˆ˜ ëª¨ë‘ í¬í•¨ë¨")
