{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "S9Vl5vvX34qH",
        "fDFAIbUz4q98",
        "94Ub81UL8lbm",
        "6d6Nv5AP58yQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "S9Vl5vvX34qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "train = pd.read_csv(\"./train.csv\")\n",
        "train = train.drop(columns=[\"id\", \"shares\"])\n",
        "test = pd.read_csv(\"./test.csv\")\n",
        "test = test.drop(columns=[\"id\"])"
      ],
      "metadata": {
        "id": "1YYrs_NG367T"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Missing value"
      ],
      "metadata": {
        "id": "fDFAIbUz4q98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train filled 3 variables\n",
        "df = pd.read_csv('train.csv')\n",
        "# 대표값 계산\n",
        "median_avg_token_length = df.loc[\n",
        "    (df['average_token_length'].notnull()) & (df['average_token_length'] != 0),\n",
        "    'average_token_length'\n",
        "].median()\n",
        "\n",
        "mean_unique_tokens = df.loc[\n",
        "    (df['n_non_stop_unique_tokens'].notnull()) & (df['n_non_stop_unique_tokens'] != 0),\n",
        "    'n_non_stop_unique_tokens'\n",
        "].mean()\n",
        "\n",
        "### Step 1. 세 변수 중 하나라도 0이면 나머지도 0\n",
        "zero_mask = (\n",
        "    (df['n_non_stop_words'] == 0) |\n",
        "    (df['n_non_stop_unique_tokens'] == 0) |\n",
        "    (df['average_token_length'] == 0)\n",
        ")\n",
        "df.loc[zero_mask, ['n_non_stop_words', 'n_non_stop_unique_tokens', 'average_token_length']] = 0\n",
        "\n",
        "### Step 2. n_non_stop_words 와 average_token_length 관계\n",
        "\n",
        "# 2-1. average_token_length만 결측이고, n_non_stop_words가 0이 아닌 경우\n",
        "mask_atl_null = df['average_token_length'].isnull() & (df['n_non_stop_words'] != 0)\n",
        "df.loc[mask_atl_null, 'average_token_length'] = median_avg_token_length\n",
        "\n",
        "# 2-2. n_non_stop_words만 결측이고, average_token_length가 0이 아닌 경우\n",
        "mask_nsw_null = df['n_non_stop_words'].isnull() & (df['average_token_length'] != 0)\n",
        "df.loc[mask_nsw_null, 'n_non_stop_words'] = 1\n",
        "\n",
        "# 2-3. 둘 다 결측인 경우\n",
        "both_null = df['n_non_stop_words'].isnull() & df['average_token_length'].isnull()\n",
        "df.loc[both_null, 'n_non_stop_words'] = 1\n",
        "df.loc[both_null, 'average_token_length'] = median_avg_token_length\n",
        "\n",
        "### Step 3. n_non_stop_words 와 n_non_stop_unique_tokens 관계\n",
        "\n",
        "# 3-1. n_non_stop_words == 0이면 나머지도 0\n",
        "mask_nsw_zero = df['n_non_stop_words'] == 0\n",
        "df.loc[mask_nsw_zero, ['n_non_stop_unique_tokens', 'average_token_length']] = 0\n",
        "\n",
        "# 3-2. n_non_stop_unique_tokens만 결측이고, n_non_stop_words가 0이 아닌 경우\n",
        "mask_unt_null = df['n_non_stop_unique_tokens'].isnull() & (df['n_non_stop_words'] != 0)\n",
        "df.loc[mask_unt_null, 'n_non_stop_unique_tokens'] = mean_unique_tokens\n",
        "\n",
        "### 결과 확인\n",
        "print(df[['n_non_stop_words', 'n_non_stop_unique_tokens', 'average_token_length']].isnull().sum())\n",
        "\n",
        "df.to_csv('train_filled_3_variables.csv', index=False)\n",
        "\n",
        "print(df[['n_non_stop_words', 'n_non_stop_unique_tokens', 'average_token_length']].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ympp3NgZFEFH",
        "outputId": "280cd114-347e-4bc2-f34e-f7b251645eb2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_non_stop_words            0\n",
            "n_non_stop_unique_tokens    0\n",
            "average_token_length        0\n",
            "dtype: int64\n",
            "n_non_stop_words            0\n",
            "n_non_stop_unique_tokens    0\n",
            "average_token_length        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test filled 3 variables\n",
        "\n",
        "df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# 대표값 계산\n",
        "median_avg_token_length = df.loc[\n",
        "    (df['average_token_length'].notnull()) & (df['average_token_length'] != 0),\n",
        "    'average_token_length'\n",
        "].median()\n",
        "\n",
        "mean_unique_tokens = df.loc[\n",
        "    (df['n_non_stop_unique_tokens'].notnull()) & (df['n_non_stop_unique_tokens'] != 0),\n",
        "    'n_non_stop_unique_tokens'\n",
        "].mean()\n",
        "\n",
        "### Step 1. 세 변수 중 하나라도 0이면 나머지도 0\n",
        "zero_mask = (\n",
        "    (df['n_non_stop_words'] == 0) |\n",
        "    (df['n_non_stop_unique_tokens'] == 0) |\n",
        "    (df['average_token_length'] == 0)\n",
        ")\n",
        "df.loc[zero_mask, ['n_non_stop_words', 'n_non_stop_unique_tokens', 'average_token_length']] = 0\n",
        "\n",
        "### Step 2. n_non_stop_words 와 average_token_length 관계\n",
        "\n",
        "# 2-1. average_token_length만 결측이고, n_non_stop_words가 0이 아닌 경우\n",
        "mask_atl_null = df['average_token_length'].isnull() & (df['n_non_stop_words'] != 0)\n",
        "df.loc[mask_atl_null, 'average_token_length'] = median_avg_token_length\n",
        "\n",
        "# 2-2. n_non_stop_words만 결측이고, average_token_length가 0이 아닌 경우\n",
        "mask_nsw_null = df['n_non_stop_words'].isnull() & (df['average_token_length'] != 0)\n",
        "df.loc[mask_nsw_null, 'n_non_stop_words'] = 1\n",
        "\n",
        "# 2-3. 둘 다 결측인 경우\n",
        "both_null = df['n_non_stop_words'].isnull() & df['average_token_length'].isnull()\n",
        "df.loc[both_null, 'n_non_stop_words'] = 1\n",
        "df.loc[both_null, 'average_token_length'] = median_avg_token_length\n",
        "\n",
        "### Step 3. n_non_stop_words 와 n_non_stop_unique_tokens 관계\n",
        "\n",
        "# 3-1. n_non_stop_words == 0이면 나머지도 0\n",
        "mask_nsw_zero = df['n_non_stop_words'] == 0\n",
        "df.loc[mask_nsw_zero, ['n_non_stop_unique_tokens', 'average_token_length']] = 0\n",
        "\n",
        "# 3-2. n_non_stop_unique_tokens만 결측이고, n_non_stop_words가 0이 아닌 경우\n",
        "mask_unt_null = df['n_non_stop_unique_tokens'].isnull() & (df['n_non_stop_words'] != 0)\n",
        "df.loc[mask_unt_null, 'n_non_stop_unique_tokens'] = mean_unique_tokens\n",
        "\n",
        "### 결과 확인\n",
        "print(df[['n_non_stop_words', 'n_non_stop_unique_tokens', 'average_token_length']].isnull().sum())\n",
        "\n",
        "df.to_csv('test_filled_3_variables.csv', index=False)\n",
        "\n",
        "print(df[['n_non_stop_words', 'n_non_stop_unique_tokens', 'average_token_length']].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRGWTtFU6L7M",
        "outputId": "7751f415-07e6-4008-8628-ec3786d09eb7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_non_stop_words            0\n",
            "n_non_stop_unique_tokens    0\n",
            "average_token_length        0\n",
            "dtype: int64\n",
            "n_non_stop_words            0\n",
            "n_non_stop_unique_tokens    0\n",
            "average_token_length        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"./train_filled_3_variables.csv\")\n",
        "test = pd.read_csv(\"./test_filled_3_variables.csv\")"
      ],
      "metadata": {
        "id": "VDweTGM5BxsV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lB4OrbhR1O2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d8a111-f20a-47ae-9c62-3e176bc370c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-08ff819cc6ab>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].mean(), inplace=True)\n",
            "<ipython-input-39-08ff819cc6ab>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(test[col].mean(), inplace=True)\n",
            "<ipython-input-39-08ff819cc6ab>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].median(), inplace=True)\n",
            "<ipython-input-39-08ff819cc6ab>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(test[col].median(), inplace=True)\n",
            "<ipython-input-39-08ff819cc6ab>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].mode().iloc[0], inplace=True)\n",
            "<ipython-input-39-08ff819cc6ab>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(test[col].mode().iloc[0], inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ 알 수 없는 전략: n_unique_tokens → linear regression with 'n_non_stop_unique_tokens' or median\n",
            "⚠️ 알 수 없는 전략: n_non_stop_words → linear regression with 'n_unique_tokens' or median\n",
            "⚠️ 알 수 없는 전략: kw_max_min → linear regression with 'kw_avg_min' or median\n",
            "⚠️ 알 수 없는 전략: kw_avg_min → linear regression with 'kw_max_min' or median\n",
            "⚠️ 알 수 없는 전략: kw_max_avg → polynomial regression with 'kw_avg_avg' or median\n",
            "⚠️ 알 수 없는 전략: kw_avg_avg → polynomial regression with 'kw_max_avg' or median\n",
            "⚠️ 알 수 없는 전략: self_reference_max_shares → linear regression with 'self_reference_avg_sharess' or median\n",
            "⚠️ 알 수 없는 전략: self_reference_avg_sharess → linear regression with 'self_reference_max_shares' or median\n",
            "⚠️ 알 수 없는 전략: global_sentiment_polarity → linear regression with 'rate_positive_words' or mean\n",
            "⚠️ 알 수 없는 전략: global_rate_negative_words → linear regression with 'rate_negative_words' or median\n",
            "⚠️ 알 수 없는 전략: rate_positive_words → linear regression with 'global_sentiment_polarity' or median\n",
            "⚠️ 알 수 없는 전략: rate_negative_words → linear regression with 'global_rate_negative_words' or median\n",
            "⚠️ 알 수 없는 전략: avg_positive_polarity → linear regression with 'max_positive_polarity' or mean\n",
            "⚠️ 알 수 없는 전략: max_positive_polarity → linear regression with 'avg_positive_polarity' or mean\n",
            "⚠️ 알 수 없는 전략: avg_negative_polarity → linear regression with 'min_negative_polarity' or mean\n",
            "⚠️ 알 수 없는 전략: min_negative_polarity → linear regression with 'avg_negative_polarity' or mean\n",
            "⚠️ 알 수 없는 전략: title_subjectivity → linear regression with 'abs_title_sentiment_polarity' or mean\n",
            "⚠️ 알 수 없는 전략: abs_title_sentiment_polarity → linear regression with 'title_subjectivity' or median\n",
            "결측치 남은 개수: 37782\n",
            "결측치 남은 개수: 16170\n"
          ]
        }
      ],
      "source": [
        "strategy_df = pd.read_csv(\"./strategy_df.csv\")\n",
        "\n",
        "strategies = strategy_df.iloc[:, 7]\n",
        "columns = strategy_df.iloc[:, 1]\n",
        "\n",
        "strategy_map = dict(zip(columns, strategies))\n",
        "\n",
        "#Central tendency\n",
        "for col, strategy in strategy_map.items():\n",
        "    if col not in train.columns:\n",
        "        continue\n",
        "    if strategy == \"mean\":\n",
        "        train[col].fillna(train[col].mean(), inplace=True)\n",
        "        test[col].fillna(test[col].mean(), inplace=True)\n",
        "    elif strategy == \"median\":\n",
        "        train[col].fillna(train[col].median(), inplace=True)\n",
        "        test[col].fillna(test[col].median(), inplace=True)\n",
        "    elif strategy == \"mode\":\n",
        "        train[col].fillna(train[col].mode().iloc[0], inplace=True)\n",
        "        test[col].fillna(test[col].mode().iloc[0], inplace=True)\n",
        "    else:\n",
        "        print(f\"⚠️ 알 수 없는 전략: {col} → {strategy}\")\n",
        "\n",
        "print(\"결측치 남은 개수:\", train.isnull().sum().sum())\n",
        "train.to_csv(\"train_clean.csv\", index = False)\n",
        "print(\"결측치 남은 개수:\", test.isnull().sum().sum())\n",
        "test.to_csv(\"test_clean.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "\n",
        "col_avg = ['n_unique_tokens', 'n_unique_tokens',\"kw_avg_min\", \"self_reference_avg_sharess\", \"global_sentiment_polarity\",\n",
        "           \"global_rate_negative_words\", \"avg_positive_polarity\", \"avg_negative_polarity\", \"title_subjectivity\"]\n",
        "col_max = ['n_non_stop_words','n_non_stop_unique_tokens', \"kw_max_min\", \"self_reference_max_shares\", \"rate_positive_words\",\n",
        "           \"rate_negative_words\", \"max_positive_polarity\", \"min_negative_polarity\", \"abs_title_sentiment_polarity\"]\n",
        "\n",
        "for i in range(len(col_avg)):\n",
        "  var_avg = col_avg[i]\n",
        "  var_max = col_max[i]\n",
        "\n",
        "# 1) 둘 다 결측치 없는 행으로 regression 학습용 데이터 준비\n",
        "  mask_both_train = train[var_avg].notna() & train[var_max].notna()\n",
        "  train_reg = train.loc[mask_both_train, [var_max, var_avg]]\n",
        "\n",
        "# 모델1: var_max → var_avg\n",
        "  model_avg = LinearRegression()\n",
        "  model_avg.fit(train_reg[[var_max]], train_reg[var_avg])\n",
        "\n",
        "# 모델2: var_avg → var_max\n",
        "  model_max = LinearRegression()\n",
        "  model_max.fit(train_reg[[var_avg]], train_reg[var_max])\n",
        "\n",
        "# 평균 토큰 결측치(var_avg)만 있는 경우\n",
        "  mask_avg_miss_train = train[var_avg].isna() & train[var_max].notna()\n",
        "  if mask_avg_miss_train.any():\n",
        "    X_pred_avg = train.loc[mask_avg_miss_train, [var_max]]\n",
        "    train.loc[mask_avg_miss_train, var_avg] = model_avg.predict(X_pred_avg)\n",
        "\n",
        "# 비중지속 토큰 결측치(var_max)만 있는 경우\n",
        "  mask_max_miss_train = train[var_max].isna() & train[var_avg].notna()\n",
        "  if mask_max_miss_train.any():\n",
        "    X_pred_max = train.loc[mask_max_miss_train, [var_avg]]\n",
        "    train.loc[mask_max_miss_train, var_max] = model_max.predict(X_pred_max)\n",
        "\n",
        "# test에도 동일하게 적용\n",
        "  mask_both_test = test[var_avg].notna() & test[var_max].notna()\n",
        "\n",
        "# 학습은 train 데이터만 사용\n",
        "  mask_avg_miss_test = test[var_avg].isna() & test[var_max].notna()\n",
        "  if mask_avg_miss_test.any():\n",
        "    Xt_pred_avg = test.loc[mask_avg_miss_test, [var_max]]\n",
        "    test.loc[mask_avg_miss_test, var_avg] = model_avg.predict(Xt_pred_avg)\n",
        "\n",
        "  mask_max_miss_test = test[var_max].isna() & test[var_avg].notna()\n",
        "  if mask_max_miss_test.any():\n",
        "    Xt_pred_max = test.loc[mask_max_miss_test, [var_avg]]\n",
        "    test.loc[mask_max_miss_test, var_max] = model_max.predict(Xt_pred_max)\n"
      ],
      "metadata": {
        "id": "x7H501ZEbv5K"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Polynomial Regression\n",
        "\n",
        "# 둘 다 값이 있는 행을 골라 학습용 데이터로 선별\n",
        "mask_train = train[\"kw_avg_avg\"].notna() & train[\"kw_max_avg\"].notna()\n",
        "df_reg_train = train.loc[mask_train, [\"kw_avg_avg\", \"kw_max_avg\"]]\n",
        "\n",
        "X_train = df_reg_train[[\"kw_avg_avg\"]]\n",
        "y_train = df_reg_train[\"kw_max_avg\"]\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_poly, y_train)\n",
        "\n",
        "# 하나만 결측치인 경우에 kw_max_avg 채우기\n",
        "mask_fill_train = train[\"kw_avg_avg\"].notna() & train[\"kw_max_avg\"].isna()\n",
        "X_pred_train = poly.transform(train.loc[mask_fill_train, [\"kw_avg_avg\"]])\n",
        "train.loc[mask_fill_train, \"kw_max_avg\"] = model.predict(X_pred_train)\n",
        "\n",
        "mask_fill_test = test[\"kw_avg_avg\"].notna() & test[\"kw_max_avg\"].isna()\n",
        "X_pred_test = poly.transform(test.loc[mask_fill_test, [\"kw_avg_avg\"]])\n",
        "test.loc[mask_fill_test, \"kw_max_avg\"] = model.predict(X_pred_test)\n",
        "\n",
        "mask_both    = train[\"kw_avg_avg\"].notna() & train[\"kw_max_avg\"].notna()\n",
        "df_both_rev  = train.loc[mask_both, [\"kw_avg_avg\", \"kw_max_avg\"]]\n",
        "\n",
        "# 설명변수 바꿔치기\n",
        "X_rev_train  = df_both_rev[[\"kw_max_avg\"]]\n",
        "y_rev_train  = df_both_rev[\"kw_avg_avg\"]\n",
        "\n",
        "poly_rev     = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_rev_poly   = poly_rev.fit_transform(X_rev_train)\n",
        "\n",
        "model_rev    = LinearRegression()\n",
        "model_rev.fit(X_rev_poly, y_rev_train)\n",
        "\n",
        "mask_fill_avg_train = train[\"kw_max_avg\"].notna() & train[\"kw_avg_avg\"].isna()\n",
        "X_pred_rev_train    = poly_rev.transform(train.loc[mask_fill_avg_train, [\"kw_max_avg\"]])\n",
        "train.loc[mask_fill_avg_train, \"kw_avg_avg\"] = model_rev.predict(X_pred_rev_train)\n",
        "\n",
        "mask_fill_avg_test  = test[\"kw_max_avg\"].notna() & test[\"kw_avg_avg\"].isna()\n",
        "X_pred_rev_test     = poly_rev.transform(test.loc[mask_fill_avg_test, [\"kw_max_avg\"]])\n",
        "test.loc[mask_fill_avg_test,  \"kw_avg_avg\"] = model_rev.predict(X_pred_rev_test)\n"
      ],
      "metadata": {
        "id": "aDZayKNedxZJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VWhjLgTiLbDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f07341-2930-4b6a-8426-79c09f9c8dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결측치 남은 개수: 0\n",
            "결측치 남은 개수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-863f3668fe72>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].mean(), inplace=True)\n",
            "<ipython-input-42-863f3668fe72>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(test[col].mean(), inplace=True)\n",
            "<ipython-input-42-863f3668fe72>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].median(), inplace=True)\n",
            "<ipython-input-42-863f3668fe72>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(test[col].median(), inplace=True)\n",
            "<ipython-input-42-863f3668fe72>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train[col].fillna(train[col].mode().iloc[0], inplace=True)\n",
            "<ipython-input-42-863f3668fe72>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(test[col].mode().iloc[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "strategy1 = pd.read_csv(\"./strategy_df(1).csv\")\n",
        "\n",
        "strategies = strategy1.iloc[:, 7]\n",
        "columns = strategy1.iloc[:, 1]\n",
        "\n",
        "strategy_map = dict(zip(columns, strategies))\n",
        "\n",
        "for col, strategy in strategy_map.items():\n",
        "    if col not in train.columns:\n",
        "        continue\n",
        "    if strategy == \"mean\":\n",
        "        train[col].fillna(train[col].mean(), inplace=True)\n",
        "        test[col].fillna(test[col].mean(), inplace=True)\n",
        "    elif strategy == \"median\":\n",
        "        train[col].fillna(train[col].median(), inplace=True)\n",
        "        test[col].fillna(test[col].median(), inplace=True)\n",
        "    elif strategy == \"mode\":\n",
        "        train[col].fillna(train[col].mode().iloc[0], inplace=True)\n",
        "        test[col].fillna(test[col].mode().iloc[0], inplace=True)\n",
        "    else:\n",
        "        print(f\"⚠️ 알 수 없는 전략: {col} → {strategy}\")\n",
        "\n",
        "print(\"결측치 남은 개수:\", train.isnull().sum().sum())\n",
        "print(\"결측치 남은 개수:\", test.isnull().sum().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('train_clean_reg.csv', index = False)\n",
        "test.to_csv('test_clean_reg.csv', index = False)"
      ],
      "metadata": {
        "id": "KEH36FGVrKRm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Outlier"
      ],
      "metadata": {
        "id": "94Ub81UL8lbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import os\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "# ==이상치 처리==\n",
        "\n",
        "# 1. 데이터 불러오기\n",
        "df = pd.read_csv('train_clean_reg.csv')\n",
        "\n",
        "# 기본 컬럼 분리\n",
        "id_col = df[['id']]\n",
        "shares_col = df[['shares']]\n",
        "y_col = df[['y']]\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "df_cat = df[cat_cols]\n",
        "\n",
        "# 수치형 변수 추출\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "exclude_cols = ['id', 'shares', 'y']\n",
        "target_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "# DBSCAN 적용할 변수쌍 정의\n",
        "dbscan_replaced_cols = [\n",
        "    'kw_max_min', 'kw_avg_min',\n",
        "    'kw_avg_avg', 'kw_max_avg',\n",
        "    'global_rate_negative_words', 'rate_negative_words',\n",
        "    'abs_title_sentiment_polarity', 'title_subjectivity'\n",
        "]\n",
        "other_cols = [col for col in target_cols if col not in dbscan_replaced_cols]\n",
        "\n",
        "# 2. 클리핑 적용 (DBSCAN 대상이 아닌 변수 전부 상하한 클리핑)\n",
        "df_clipped = df.copy()\n",
        "for col in other_cols:\n",
        "    lower = df[col].quantile(0.05)\n",
        "    upper = df[col].quantile(0.95)\n",
        "    df_clipped[col] = np.clip(df[col], lower, upper)\n",
        "\n",
        "# 3. DBSCAN 이상치 대체\n",
        "df_num = df_clipped[target_cols].copy()  # 클리핑된 값에서 시작\n",
        "\n",
        "# 변수쌍별 DBSCAN 파라미터\n",
        "feature_pairs = [\n",
        "    (['kw_max_min', 'kw_avg_min'], {'eps': 2000, 'min_samples': 20}),\n",
        "    (['kw_avg_avg', 'kw_max_avg'], {'eps': 2500, 'min_samples': 8}),\n",
        "    (['global_rate_negative_words', 'rate_negative_words'], {'eps': 0.015, 'min_samples': 40}),\n",
        "    (['abs_title_sentiment_polarity', 'title_subjectivity'], {'eps': 0.07, 'min_samples': 70}),\n",
        "]\n",
        "\n",
        "for features, params in feature_pairs:\n",
        "    var1, var2 = features\n",
        "    df_pair = df_num[features].dropna()\n",
        "    X = df_pair.values\n",
        "\n",
        "    # DBSCAN\n",
        "    dbscan = DBSCAN(eps=params['eps'], min_samples=params['min_samples'])\n",
        "    labels = dbscan.fit_predict(X)\n",
        "    outlier_mask = labels == -1\n",
        "    normal_mask = labels != -1\n",
        "\n",
        "    print(f\"{features}: 이상치 개수 = {np.sum(outlier_mask)}\")\n",
        "\n",
        "    # 가장 가까운 정상치로 대체\n",
        "    X_replaced = X.copy()\n",
        "    if np.sum(outlier_mask) > 0:\n",
        "        nn = NearestNeighbors(n_neighbors=1)\n",
        "        nn.fit(X[normal_mask])\n",
        "        distances, indices = nn.kneighbors(X[outlier_mask])\n",
        "        X_replaced[outlier_mask] = X[normal_mask][indices.flatten()]\n",
        "\n",
        "    # 반영\n",
        "    df_num.loc[df_pair.index, var1] = X_replaced[:, 0]\n",
        "    df_num.loc[df_pair.index, var2] = X_replaced[:, 1]\n",
        "\n",
        "# DBSCAN 처리된 변수만 df_clipped에 덮어쓰기\n",
        "for features, _ in feature_pairs:\n",
        "    var1, var2 = features\n",
        "    df_clipped[var1] = df_num[var1]\n",
        "    df_clipped[var2] = df_num[var2]\n",
        "\n",
        "# 4. 최종 결합\n",
        "df_final = pd.concat([id_col, df_clipped[target_cols], df_cat, shares_col, y_col], axis=1)\n",
        "\n",
        "# 5. 저장\n",
        "df_final.to_csv(\"train_outlier.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_FJleGyPmyk",
        "outputId": "b98fab3d-7d15-45a1-c03b-1b6d946ab6ae"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['kw_max_min', 'kw_avg_min']: 이상치 개수 = 46\n",
            "['kw_avg_avg', 'kw_max_avg']: 이상치 개수 = 59\n",
            "['global_rate_negative_words', 'rate_negative_words']: 이상치 개수 = 205\n",
            "['abs_title_sentiment_polarity', 'title_subjectivity']: 이상치 개수 = 254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. 데이터 불러오기\n",
        "df = pd.read_csv('test_clean_reg.csv')\n",
        "\n",
        "# 기본 컬럼 분리\n",
        "id_col = df[['id']]\n",
        "cat_cols = df.select_dtypes(include='object').columns\n",
        "df_cat = df[cat_cols]\n",
        "\n",
        "# 수치형 변수 추출\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "exclude_cols = ['id']\n",
        "target_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "# DBSCAN 적용할 변수쌍 정의\n",
        "dbscan_replaced_cols = [\n",
        "    'kw_max_min', 'kw_avg_min',\n",
        "    'kw_avg_avg', 'kw_max_avg',\n",
        "    'global_rate_negative_words', 'rate_negative_words',\n",
        "    'abs_title_sentiment_polarity', 'title_subjectivity'\n",
        "]\n",
        "other_cols = [col for col in target_cols if col not in dbscan_replaced_cols]\n",
        "\n",
        "# 2. 클리핑 적용 (DBSCAN 대상이 아닌 변수 전부 상하한 클리핑)\n",
        "df_clipped = df.copy()\n",
        "for col in other_cols:\n",
        "    lower = df[col].quantile(0.05)\n",
        "    upper = df[col].quantile(0.95)\n",
        "    df_clipped[col] = np.clip(df[col], lower, upper)\n",
        "\n",
        "# 3. DBSCAN 이상치 대체\n",
        "df_num = df_clipped[target_cols].copy()  # 클리핑된 값에서 시작\n",
        "\n",
        "# 변수쌍별 DBSCAN 파라미터\n",
        "feature_pairs = [\n",
        "    (['kw_max_min', 'kw_avg_min'], {'eps': 2000, 'min_samples': 20}),\n",
        "    (['kw_avg_avg', 'kw_max_avg'], {'eps': 2500, 'min_samples': 8}),\n",
        "    (['global_rate_negative_words', 'rate_negative_words'], {'eps': 0.015, 'min_samples': 40}),\n",
        "    (['abs_title_sentiment_polarity', 'title_subjectivity'], {'eps': 0.07, 'min_samples': 70}),\n",
        "]\n",
        "\n",
        "for features, params in feature_pairs:\n",
        "    var1, var2 = features\n",
        "    df_pair = df_num[features].dropna()\n",
        "    X = df_pair.values\n",
        "\n",
        "    # DBSCAN\n",
        "    dbscan = DBSCAN(eps=params['eps'], min_samples=params['min_samples'])\n",
        "    labels = dbscan.fit_predict(X)\n",
        "    outlier_mask = labels == -1\n",
        "    normal_mask = labels != -1\n",
        "\n",
        "    print(f\"{features}: 이상치 개수 = {np.sum(outlier_mask)}\")\n",
        "\n",
        "    # 가장 가까운 정상치로 대체\n",
        "    X_replaced = X.copy()\n",
        "    if np.sum(outlier_mask) > 0:\n",
        "        nn = NearestNeighbors(n_neighbors=1)\n",
        "        nn.fit(X[normal_mask])\n",
        "        distances, indices = nn.kneighbors(X[outlier_mask])\n",
        "        X_replaced[outlier_mask] = X[normal_mask][indices.flatten()]\n",
        "\n",
        "    # 반영\n",
        "    df_num.loc[df_pair.index, var1] = X_replaced[:, 0]\n",
        "    df_num.loc[df_pair.index, var2] = X_replaced[:, 1]\n",
        "\n",
        "# DBSCAN 처리된 변수만 df_clipped에 덮어쓰기\n",
        "for features, _ in feature_pairs:\n",
        "    var1, var2 = features\n",
        "    df_clipped[var1] = df_num[var1]\n",
        "    df_clipped[var2] = df_num[var2]\n",
        "\n",
        "# 4. 최종 결합\n",
        "df_final = pd.concat([id_col, df_clipped[target_cols], df_cat], axis=1)\n",
        "\n",
        "# 5. 저장\n",
        "df_final.to_csv(\"test_outlier.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kv4y869PuZ0",
        "outputId": "346468f4-7a77-41c2-ac33-e0c9ccf33f70"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['kw_max_min', 'kw_avg_min']: 이상치 개수 = 50\n",
            "['kw_avg_avg', 'kw_max_avg']: 이상치 개수 = 41\n",
            "['global_rate_negative_words', 'rate_negative_words']: 이상치 개수 = 151\n",
            "['abs_title_sentiment_polarity', 'title_subjectivity']: 이상치 개수 = 546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoding"
      ],
      "metadata": {
        "id": "6d6Nv5AP58yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "train = pd.read_csv(\"./train_outlier.csv\")\n",
        "test = pd.read_csv(\"./test_outlier.csv\")\n",
        "categorical_cols = [\"data_channel\", \"weekday\"]\n",
        "\n",
        "#One-Hot Encoder 설정\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "\n",
        "train_ohe = pd.DataFrame(\n",
        "    ohe.fit_transform(train[categorical_cols]),\n",
        "    columns=ohe.get_feature_names_out(categorical_cols),\n",
        "    index=train.index)\n",
        "\n",
        "test_ohe = pd.DataFrame(\n",
        "    ohe.transform(test[categorical_cols]), #train set과 동일하게 정리\n",
        "    columns=ohe.get_feature_names_out(categorical_cols),\n",
        "    index=test.index)\n",
        "\n",
        "#원본에서 범주형 컬럼 제거하고, 인코딩된 컬럼 붙이기\n",
        "train  = pd.concat([train.drop(columns=categorical_cols), train_ohe ], axis=1)\n",
        "test  = pd.concat([test.drop(columns=categorical_cols), test_ohe ], axis=1)\n",
        "\n",
        "train.to_csv(\"./train_encoded.csv\", index =False)\n",
        "test.to_csv(\"./test_encoded.csv\",  index=False)"
      ],
      "metadata": {
        "id": "Vsp62eYbP61V"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Variable Selection"
      ],
      "metadata": {
        "id": "WqXsKrfi-_vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def drop_outliers(df: pd.DataFrame, drop_path: str) -> pd.DataFrame:\n",
        "    if os.path.exists(drop_path):\n",
        "        rows_to_drop = pd.read_csv(drop_path, header=None).squeeze().tolist()\n",
        "        df = df.drop(index=rows_to_drop)\n",
        "        print(f\"✅ Dropped {len(rows_to_drop)} rows from train\")\n",
        "    else:\n",
        "        print(\"⚠️ rows_to_drop.csv not found.\")\n",
        "    return df\n",
        "\n",
        "def select_features(df: pd.DataFrame) -> list:\n",
        "    dummy_cols = [col for col in df.columns if col.startswith('data_channel_') or col.startswith('weekday_')]\n",
        "    numeric_cols = [col for col in df.columns if col not in dummy_cols and col not in {'id', 'shares', 'y'}]\n",
        "\n",
        "    df_numeric = df[numeric_cols]\n",
        "\n",
        "    # 1. 분산 기준 완화\n",
        "    vt = VarianceThreshold(threshold=0.0005)  # 기존 0.001에서 완화\n",
        "    vt.fit(df_numeric)\n",
        "    low_var = df_numeric.columns[~vt.get_support()]\n",
        "\n",
        "    # 2. 상관계수 기준 완화\n",
        "    corr = df_numeric.corr().abs()\n",
        "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "    high_corr = [c for c in upper.columns if any(upper[c] > 0.98)]  # 기존 0.95에서 완화\n",
        "\n",
        "    # 3. VIF 기준 완화\n",
        "    vif_vals = [variance_inflation_factor(df_numeric.values, i) for i in range(df_numeric.shape[1])]\n",
        "    vif_drop = df_numeric.columns[np.array(vif_vals) > 20]  # 기존 15에서 완화\n",
        "\n",
        "    # 4. 사용자 정의 변수 보호\n",
        "    protected_vars = {'kw_avg_min', 'global_sentiment_polarity'}\n",
        "    drop_cols = set(low_var) | set(high_corr) | set(vif_drop) - protected_vars\n",
        "\n",
        "    # 5. 최종 변수 리스트\n",
        "    final_numeric = [c for c in numeric_cols if c not in drop_cols]\n",
        "    final_cols = final_numeric + dummy_cols\n",
        "    return final_cols\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_raw = pd.read_csv(\"./train_encoded.csv\")\n",
        "    test = pd.read_csv(\"./test_encoded.csv\")\n",
        "\n",
        "    # 1. 이상치 제거\n",
        "    train_cleaned = drop_outliers(train_raw, \"./rows_to_drop.csv\")\n",
        "\n",
        "    # 2. y 분리\n",
        "    y = train_cleaned['y']\n",
        "    train_features_only = train_cleaned.drop(columns=['y'])\n",
        "\n",
        "    # 3. 변수 선택\n",
        "    selected_cols = select_features(train_cleaned)\n",
        "\n",
        "    # 4. train: 선택된 컬럼 + y 병합\n",
        "    X_train_selected = train_features_only[selected_cols]\n",
        "    train_selected = pd.concat([X_train_selected, y], axis=1)\n",
        "    train_selected.to_csv(\"./train_selected.csv\", index=False)\n",
        "\n",
        "    # 5. test: 선택된 컬럼만 사용\n",
        "    test_selected = test[[col for col in selected_cols if col in test.columns]]\n",
        "    test_selected.to_csv(\"./test_selected.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJBJeiIe_Cjn",
        "outputId": "2436407b-abae-49ed-fdf0-9fd701c006ed"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dropped 299 rows from train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Standardization"
      ],
      "metadata": {
        "id": "_d6r9TRPBMsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv(\"./test_selected.csv\")\n",
        "\n",
        "# 뒤쪽 13개 열 떼어내기 (범주형 변수 인코딩한 열)\n",
        "df_tail = df.iloc[:, -13:]\n",
        "\n",
        "# 앞쪽 수치형 변수만 선택\n",
        "df_numeric = df.iloc[:, :-13]\n",
        "\n",
        "# 왜도 확인\n",
        "skewness = df_numeric.skew()\n",
        "\n",
        "# 왜도 절대값 > 1인 열들에 로그 변환 적용\n",
        "high_skew_cols = skewness[skewness.abs() > 1.0].index\n",
        "\n",
        "for col in high_skew_cols:\n",
        "    min_val = df_numeric[col].min()\n",
        "\n",
        "    # 모든 값이 0보다 크면 그대로 로그 변환\n",
        "    if min_val >= 0:\n",
        "        df_numeric[col] = np.log1p(df_numeric[col])  # log(1 + x) 안정적\n",
        "    else:\n",
        "        # 음수나 0이 있는 경우: 값을 양수로 이동 후 로그 변환\n",
        "        shift = 1 - min_val\n",
        "        df_numeric[col] = np.log1p(df_numeric[col] + shift)\n",
        "\n",
        "\n",
        "# 수치형 전체에 StandardScaler 적용\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df_numeric)\n",
        "\n",
        "# 최종 버전 구성\n",
        "df_scaled = pd.DataFrame(scaled_data, columns=df_numeric.columns)\n",
        "df_final = pd.concat([df_scaled, df_tail], axis=1)\n",
        "\n",
        "# 저장 및 확인\n",
        "df_final.to_csv(\"test_final.csv\", index=False)"
      ],
      "metadata": {
        "id": "VyJbB05PBfcW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prediction"
      ],
      "metadata": {
        "id": "QP_SBI8OlpPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import joblib\n",
        "model_path = './stacking_model.pkl'\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "test = pd.read_csv(\"./test_final.csv\")\n",
        "test_raw = pd.read_csv(\"./test.csv\")\n",
        "\n",
        "# ID 처리\n",
        "test_id = test_raw[\"id\"]  # ✅ test.csv 기준으로 id 사용\n",
        "\n",
        "y_prob = model.predict_proba(test)[:, 1]\n",
        "y_pred = (y_prob >= 0.44).astype(int)  # ✅ Best Threshold = 0.44\n",
        "\n",
        "# 4. 결과 저장\n",
        "pd.DataFrame({\n",
        "    \"id\": test_id,\n",
        "    \"y_prob\": y_prob,\n",
        "    \"y_predict\": y_pred\n",
        "}).to_csv(\"./prediction.csv\", index=False)\n",
        "files.download(\"./prediction.csv\")"
      ],
      "metadata": {
        "id": "K8-gMHFBlmQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "3d931fd1-6862-42a4-dbe8-53338d321c1e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4c4b2b2-582c-4881-a8aa-bcf40833482e\", \"prediction.csv\", 255958)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}